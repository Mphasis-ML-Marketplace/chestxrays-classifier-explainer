{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0ac818c",
   "metadata": {},
   "source": [
    "# BYOM Image Classifier Xplainer\n",
    "\n",
    "ChestDetect X-AI is an advanced deep learning solution specifically designed for chest X-ray diagnosis. The solution utilizes SOTA DL model to detect and diagnose the medical conditions such as COVID-19, Lung opacity, and Viral Pneumonia. It generates activation map and highlights the respective X-ray images that explains the presence of any of the three medical conditions. \n",
    "\n",
    "### Prerequisite\n",
    "\n",
    "To run this algorithm you need to have access to the following AWS Services:\n",
    "- Access to AWS SageMaker and the model package.\n",
    "- An S3 bucket to specify input/output.\n",
    "- Role for AWS SageMaker to access input/output from S3.\n",
    "\n",
    "This sample notebook shows you how to deploy medical xai using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to Synthetic Data Evaluation. If so, skip step: [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   4. [Output Result](#D.-Output-Result)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "3. [Perform batch inference](#3.-Perform-batch-inference) \n",
    "4. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "    \n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4c5fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a6e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_arn='byom-image-xplainer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52aa2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "from zipfile import ZipFile\n",
    "import uuid\n",
    "\n",
    "import sagemaker as sage\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sage.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d46036",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = \n",
    "content_type = \"application/zip\"\n",
    "\n",
    "batch_transform_inference_instance_type = \"ml.m5.xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de4b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.predictor.Predictor(endpoint, session, content_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelPackage(role=role,\n",
    "                    model_package_arn=model_package_arn, \n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    predictor_cls=predict_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7329b809",
   "metadata": {},
   "source": [
    "### 2. Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dda54d3",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together. If you are not familiar with batch transform, and want to learn more, see these links:\n",
    "1. [How it works](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html)\n",
    "2. [How to run a batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d15b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_folder = \"byom-image-xplainer-demo-test\"\n",
    "transform_input_folder = 'batch-inference-input/Inputs.zip'\n",
    "transform_input = sagemaker_session.upload_data(transform_input_folder, key_prefix=bucket_folder) \n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the batch inference job\n",
    "transformer = model.transformer(1, batch_transform_inference_instance_type, max_payload=60)\n",
    "transformer.transform(transform_input, content_type=content_type)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a16134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ouput is available on the following path\n",
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b01bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_conn = boto3.client(\"s3\")\n",
    "bucket_name = \"sagemaker-us-east-2-786796469737\"\n",
    "\n",
    "with open(\"batch-inference-output/response.zip\", \"wb\") as f:\n",
    "    s3_conn.download_fileobj(bucket_name, os.path.basename(transformer.output_path)+\"/Inputs.zip.out\", f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02a4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip batch-inference-output/response.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedecb58",
   "metadata": {},
   "source": [
    "### 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0a40a1",
   "metadata": {},
   "source": [
    "#### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01446e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6556de",
   "metadata": {},
   "source": [
    "#### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1628a717",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
