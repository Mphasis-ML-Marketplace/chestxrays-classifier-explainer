# explainable-ai-for-image-classification

# Product overview
Explainable AI for Image Classification is designed to diagnose robustness and explainability of model predictions during model development process and production stages. The solution helps developers to ensure transparency and interpretability in deep learning models for computer vision tasks. It generates activation maps of the images highlighting the most important features the model learned for classification. For example, for defect detection in circuit board manufacting, the model might highlight defected solder joints or speciifc components on the circuit board. This solution also demonstrates the confidence scores of the explanations quantifying the interpretability of ML models.

# Product Highlight
- Explainable AI for Image Classification inputs pytorch based deep learning models trained on specific tasks and provides explainibility of model predictions with confidence scores. This solution can aid in explaining model predictions for computer vision tasks in the fields of medical imaging & diagnosis, statellite imaging, detecting defects and anamolies in manufacturing etc.
- Explainable AI for Image Classification provides confidence score of explainability using advanced evaluation framework. The confidence score and evaluation framework evaluates the explanation based on features with least and most attention. The value of metric ranges from -1 to 1, with higher positive value depicting good explanation capability.
- PACE - ML is Mphasis Framework and Methodology for end-to-end machine learning development and deployment. PACE-ML enables organizations to improve the quality & reliability of the machine learning solutions in production and helps automate, scale, and monitor them. Need customized Machine Learning and Deep Learning solutions? Get in touch!

# Amazon Marketplace Link
The product can be found here
